{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thulac\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import re\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "Cutter = thulac.thulac(seg_only=True)\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "max_one_sentence_word_num = 128\n",
    "max_one_document_sentence_num = 32\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "dropout_rate = 0.5\n",
    "batch_size = 512\n",
    "epoch_num = 16\n",
    "filters = 64\n",
    "min_gram = 2\n",
    "max_gram = 5\n",
    "window_sizes = [2, 3, 4, 5]\n",
    "embedding_dim = 200\n",
    "\n",
    "\n",
    "with open(\"law.txt\", 'r', encoding='utf-8') as f:\n",
    "    article_num = len(f.readlines())\n",
    "with open(\"accu.txt\", 'r', encoding='utf-8') as f:\n",
    "    accusation_num = len(f.readlines())\n",
    "penalty_num = 11\n",
    "\n",
    "\n",
    "def load_mapping(file_path):\n",
    "    id_to_name = {}\n",
    "    name_to_id = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            name = line.strip()\n",
    "            id_to_name[idx] = [name]\n",
    "            name_to_id[name] = idx\n",
    "    return id_to_name, name_to_id\n",
    "\n",
    "id_to_article, article_to_id = load_mapping(\"law.txt\")\n",
    "article_num = len(id_to_article)\n",
    "print(f\"article_num: {article_num}\")\n",
    "print(f\"Sample id_to_article: {dict(list(id_to_article.items())[:5])}\")\n",
    "print(f\"Sample article_to_id: {dict(list(article_to_id.items())[:5])}\")\n",
    "\n",
    "id_to_crime, crime_to_id = load_mapping(\"accu.txt\")\n",
    "accusation_num = len(id_to_crime)\n",
    "print(f\"accusation_num: {accusation_num}\")\n",
    "\n",
    "\n",
    "def load_w2v_matrix(numpy_path: str, w2id_path: str):\n",
    "    with open(w2id_path, 'rb') as f:\n",
    "        word2id_dict = pk.load(f)\n",
    "    array = np.load(numpy_path)\n",
    "    if not isinstance(array, np.ndarray):\n",
    "        raise TypeError(f\"Expected np.ndarray, got {type(array)}\")\n",
    "    word_embedding = torch.from_numpy(array.astype(np.float32))\n",
    "    return word_embedding, word2id_dict\n",
    "\n",
    "w, d = load_w2v_matrix(\"cail_thulac.npy\", \"w2id_thulac.pkl\")\n",
    "print(\"Model loaded succeed\")\n",
    "\n",
    "def transform_word2id(word):\n",
    "    return d.get(word, d[\"BLANK\"])\n",
    "\n",
    "\n",
    "def convert_imprisonment_to_term(tempterm):\n",
    "    if tempterm[\"death_penalty\"] == True or tempterm[\"life_imprisonment\"] == True or tempterm[\"imprisonment\"] == -1 or tempterm[\"imprisonment\"] == -2:\n",
    "        return 0\n",
    "    else:\n",
    "        imprisonment = tempterm[\"imprisonment\"]\n",
    "        if imprisonment > 10 * 12:\n",
    "            return 1\n",
    "        elif imprisonment > 7 * 12:\n",
    "            return 2\n",
    "        elif imprisonment > 5 * 12:\n",
    "            return 3\n",
    "        elif imprisonment > 3 * 12:\n",
    "            return 4\n",
    "        elif imprisonment > 2 * 12:\n",
    "            return 5\n",
    "        elif imprisonment > 1 * 12:\n",
    "            return 6\n",
    "        elif imprisonment > 9:\n",
    "            return 7\n",
    "        elif imprisonment > 6:\n",
    "            return 8\n",
    "        elif imprisonment > 0:\n",
    "            return 9\n",
    "        else:\n",
    "            return 10\n",
    "\n",
    "\n",
    "def map_term_to_months(term_idx):\n",
    "    term_to_months = {\n",
    "        0: 216,   # death_penalty or life_imprisonment -> 18 years (216 months)\n",
    "        1: 168,   # (120, 216) -> 168 months\n",
    "        2: 102,   # (84, 120] -> 102 months\n",
    "        3: 72,    # (60, 84] -> 72 months\n",
    "        4: 48,    # (36, 60] -> 48 months\n",
    "        5: 30,    # (24, 36] -> 30 months\n",
    "        6: 18,    # (12, 24] -> 18 months\n",
    "        7: 10.5,  # (9, 12] -> 10.5 months\n",
    "        8: 7.5,   # (6, 9] -> 7.5 months\n",
    "        9: 3,     # (0, 6] -> 3 months\n",
    "        10: 0     # 0\n",
    "    }\n",
    "    return term_to_months.get(term_idx, -3)  # -3 indicates an invalid prediction\n",
    "\n",
    "\n",
    "\n",
    "def load_jsonlines(file_path):\n",
    "    data = []\n",
    "    skipped_lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            cleaned_line = line.strip().strip('\"')\n",
    "            if not cleaned_line:\n",
    "                continue\n",
    "            try:\n",
    "                item = json.loads(cleaned_line)\n",
    "                data.append(item)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning - Parsing error on line {line_num}: {e}, Line content: {cleaned_line}\")\n",
    "                skipped_lines.append((line_num, cleaned_line))\n",
    "                default_item = {\n",
    "                    \"meta\": {\n",
    "                        \"relevant_articles\": [],\n",
    "                        \"accusation\": [],\n",
    "                        \"term_of_imprisonment\": {\"imprisonment\": -3, \"death_penalty\": False, \"life_imprisonment\": False}\n",
    "                    }\n",
    "                }\n",
    "                data.append(default_item)\n",
    "    if skipped_lines:\n",
    "        print(f\"Skipped {len(skipped_lines)} lines of invalid data, but default values were filled to maintain the same number of lines\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_imprisonment_score(true_imprisonments, pred_imprisonments):\n",
    "    score_list = []\n",
    "    abstentions = 0\n",
    "    max_imprisonment = 216\n",
    "    \n",
    "    for true, pred in zip(true_imprisonments, pred_imprisonments):\n",
    "        true_term = true[0]\n",
    "        pred_term = pred[0]\n",
    "        \n",
    "        true_term = max_imprisonment if true_term in [-2, -1] else true_term\n",
    "        pred_term = max_imprisonment if pred_term in [-2, -1] else pred_term\n",
    "        \n",
    "        if pred_term == -3:\n",
    "            abstentions += 1\n",
    "            score_list.append(math.log(max_imprisonment))\n",
    "            continue\n",
    "        \n",
    "        if true_term < 0 or pred_term < 0:\n",
    "            continue\n",
    "        \n",
    "        score_list.append(abs(math.log(true_term + 1) - math.log(pred_term + 1)))\n",
    "    \n",
    "    if not score_list:\n",
    "        return {\"score\": 0, \"abstention_rate\": 1.0}\n",
    "    \n",
    "    log_distance = sum(score_list) / len(score_list)\n",
    "    normalized_score = (math.log(max_imprisonment) - log_distance) / math.log(max_imprisonment)\n",
    "    \n",
    "    return {\n",
    "        \"score\": normalized_score,\n",
    "        \"abstention_rate\": abstentions / len(true_imprisonments)\n",
    "    }\n",
    "\n",
    "\n",
    "def preprocess_and_cache(file_path, cache_path):\n",
    "    global d\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading cached data from {cache_path}\")\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            data = pk.load(f)\n",
    "        for i, (fact, article, accusation, penalty) in enumerate(data[:5]):\n",
    "            print(f\"Cached sample {i}: article={article}, accusation={accusation}\")\n",
    "        return data\n",
    "    \n",
    "    print(f\"Generating cache for {file_path}\")\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file, desc=f\"Preprocessing {file_path}\"):\n",
    "            d_local = json.loads(line.strip())\n",
    "            fact = [transform_word2id(w[0]) if isinstance(w, list) and w else d[\"BLANK\"]\n",
    "                    for w in Cutter.cut(d_local['fact'])\n",
    "                    if isinstance(w, list) and w and w[0] not in [\",\", \".\", \"?\", \"\\\"\", \"”\", \"。\", \"？\", \"\", \"，\", \",\", \"、\", \"”\"]]\n",
    "            min_length = min(window_sizes)\n",
    "            if len(fact) < min_length:\n",
    "                fact.extend([d[\"BLANK\"]] * (min_length - len(fact)))\n",
    "            \n",
    "            \n",
    "            article_raw = d_local['meta']['relevant_articles']\n",
    "            article_labels = []\n",
    "            for art in article_raw:\n",
    "                art_str = str(art)\n",
    "                if art_str in article_to_id:\n",
    "                    article_labels.append(article_to_id[art_str])\n",
    "                else:\n",
    "                    print(f\"Warning: Article {art_str} not in article_to_id\")\n",
    "            if not article_labels:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            accusation_raw = d_local['meta']['accusation']\n",
    "            accusation_labels = []\n",
    "            for acc in accusation_raw:\n",
    "                acc_clean = re.sub(r\"[\\[\\]]\", \"\", acc).strip()\n",
    "                if acc_clean in crime_to_id:\n",
    "                    accusation_labels.append(crime_to_id[acc_clean])\n",
    "                else:\n",
    "                    print(f\"Warning: Accusation {acc_clean} not in crime_to_id\")\n",
    "            if not accusation_labels:\n",
    "                continue\n",
    "            \n",
    "            penalty = convert_imprisonment_to_term(d_local['meta']['term_of_imprisonment'])\n",
    "            data.append((fact, article_labels, accusation_labels, penalty))\n",
    "    \n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pk.dump(data, f)\n",
    "    print(f\"Data cached to {cache_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "class DataAdapterDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        file_path = 'train_data94835.json' if mode == 'train' else 'test_data7050.json'\n",
    "\n",
    "        # cache\n",
    "        if mode == 'train':\n",
    "            cache_path = f\"{mode}94835_cache.pkl\"\n",
    "        if mode == 'test':\n",
    "            cache_path = f\"{mode}7050_cache.pkl\"\n",
    "        \n",
    "        self.data = preprocess_and_cache(file_path, cache_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    facts = [item[0] for item in batch]\n",
    "    max_len = min(max(len(f) for f in facts), max_one_sentence_word_num * max_one_document_sentence_num)\n",
    "    fact_tensor = torch.zeros(len(batch), max_one_document_sentence_num, max_one_sentence_word_num, dtype=torch.long)\n",
    "    for i, f in enumerate(facts):\n",
    "        sent_idx = 0\n",
    "        word_idx = 0\n",
    "        for word in f[:max_len]:\n",
    "            if word_idx >= max_one_sentence_word_num:\n",
    "                word_idx = 0\n",
    "                sent_idx += 1\n",
    "            if sent_idx >= max_one_document_sentence_num:\n",
    "                break\n",
    "            fact_tensor[i, sent_idx, word_idx] = word\n",
    "            word_idx += 1\n",
    "\n",
    "    article_labels = torch.zeros(len(batch), article_num, dtype=torch.float)\n",
    "    for i, labels in enumerate([item[1] for item in batch]):\n",
    "        for lbl in labels:\n",
    "            if lbl < article_num:\n",
    "                article_labels[i, lbl] = 1.0\n",
    "\n",
    "    accusation_labels = torch.zeros(len(batch), accusation_num, dtype=torch.float)\n",
    "    for i, labels in enumerate([item[2] for item in batch]):\n",
    "        for lbl in labels:\n",
    "            if lbl < accusation_num:\n",
    "                accusation_labels[i, lbl] = 1.0\n",
    "\n",
    "    penalty_labels = torch.tensor([item[3] for item in batch], dtype=torch.long)\n",
    "    return fact_tensor, article_labels, accusation_labels, penalty_labels\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    DataAdapterDataset('train'), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=min(multiprocessing.cpu_count(), 4),\n",
    "    pin_memory=True,\n",
    "    drop_last=False, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    DataAdapterDataset('test'), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=min(multiprocessing.cpu_count(), 4), \n",
    "    pin_memory=True,\n",
    "    drop_last=False, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"Train samples:\", len(dataloader.dataset))\n",
    "print(\"Test samples:\", len(test_dataloader.dataset))\n",
    "print(\"Train batches:\", len(dataloader))\n",
    "print(\"Test batches:\", len(test_dataloader))\n",
    "\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, filters, (k, embedding_dim)) for k in range(min_gram, max_gram + 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        sample_num = x.size(0)\n",
    "        sentence_num = x.size(1)\n",
    "        sentence_len = x.size(2)\n",
    "        x = x.view(sample_num, 1, -1, embedding_dim)\n",
    "        conv_out = []\n",
    "        gram=min_gram\n",
    "        for conv in self.convs:\n",
    "            y = F.relu(conv(x)).view(sample_num, filters, -1)\n",
    "            y = F.max_pool1d(y, kernel_size=sentence_num * sentence_len - gram + 1).view(sample_num, -1)\n",
    "            conv_out.append(y)\n",
    "            gram += 1\n",
    "        conv_out = torch.cat(conv_out, dim=1)\n",
    "        return conv_out.view(-1, (max_gram - min_gram + 1) * filters)\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.feature_len = hidden_size\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.outfc = nn.ModuleList([nn.Linear(hidden_size, article_num), nn.Linear(hidden_size, accusation_num), nn.Linear(hidden_size, penalty_num)])\n",
    "        self.midfc = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(3)])\n",
    "        self.cell_list = nn.ModuleList([None] + [nn.LSTMCell(hidden_size, hidden_size) for _ in range(3)])\n",
    "        self.hidden_state_fc_list = nn.ModuleList([nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(4)]) for _ in range(4)])\n",
    "        self.cell_state_fc_list = nn.ModuleList([nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(4)]) for _ in range(4)])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.hidden_list = [(torch.zeros(batch_size, self.hidden_dim).to(device), torch.zeros(batch_size, self.hidden_dim).to(device)) for _ in range(4)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        sample_num = x.size(0)\n",
    "        self.init_hidden(sample_num)\n",
    "        outputs = []\n",
    "        graph = generate_graph()\n",
    "        first = [True] * 4\n",
    "        for a in range(1, 4):\n",
    "            hx, cx = self.hidden_list[a]\n",
    "            h, c = self.cell_list[a](x, (hx, cx))\n",
    "            for b in range(1, 4):\n",
    "                if graph[a][b]:\n",
    "                    hp, cp = self.hidden_list[b]\n",
    "                    if first[b]:\n",
    "                        first[b] = False\n",
    "                        hp, cp = h, c\n",
    "                    else:\n",
    "                        hp = hp + self.hidden_state_fc_list[a][b](h)\n",
    "                        cp = cp + self.cell_state_fc_list[a][b](c)\n",
    "                    self.hidden_list[b] = (hp, cp)\n",
    "            \n",
    "            output = self.outfc[a - 1](h).view(sample_num, -1)\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "def generate_graph():\n",
    "    s = \"[(1 2),(2 3),(1 3)]\"\n",
    "    arr = s.replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")\n",
    "    graph = []\n",
    "    n = 0\n",
    "    if s == \"[]\":\n",
    "        arr = []\n",
    "        n = 3\n",
    "    for a in range(len(arr)):\n",
    "        arr[a] = arr[a].replace(\"(\", \"\").replace(\")\", \"\").split()\n",
    "        arr[a][0] = int(arr[a][0])\n",
    "        arr[a][1] = int(arr[a][1])\n",
    "        n = max(n, max(arr[a][0], arr[a][1]))\n",
    "    n += 1\n",
    "    for a in range(n):\n",
    "        graph.append([False] * n)\n",
    "    for a in range(len(arr)):\n",
    "        graph[arr[a][0]][arr[a][1]] = True\n",
    "    return graph\n",
    "\n",
    "class TopJudge(nn.Module):\n",
    "    def __init__(self, embedding: np.array, dropout_rate: float = dropout_rate):\n",
    "        super(TopJudge, self).__init__()\n",
    "        self.embs = nn.Embedding(164673, 200)\n",
    "        self.embs.weight.data.copy_(embedding)\n",
    "        self.embs.weight.requires_grad = False\n",
    "        self.encoder = CNNEncoder()\n",
    "        self.decoder = LSTMDecoder()\n",
    "        self.dropout = nn.Dropout(dropout_rate)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embs(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = TopJudge(w).to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion_multi = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([50.0]).to(device))\n",
    "criterion_single = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epoch_num}\")):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        facts_embedding = batch[0].to(device)\n",
    "        article_labels = batch[1].to(device)\n",
    "        accusation_labels = batch[2].to(device)\n",
    "        penalty_labels = batch[3].to(device)\n",
    "\n",
    "        o = model(facts_embedding)\n",
    "        \n",
    "        if torch.isnan(o[2]).any() or torch.isinf(o[2]).any():\n",
    "            print(f\"Step {step+1}: o[2] contains nan or inf: {o[2]}\")\n",
    "            break\n",
    "        \n",
    "        loss1 = criterion_multi(o[0], article_labels)\n",
    "        loss2 = criterion_multi(o[1], accusation_labels)\n",
    "        loss3 = criterion_single(o[2], penalty_labels)\n",
    "        loss = loss1 + loss2 + loss3\n",
    "        loss.backward()\n",
    "        print(f\"Epoch {epoch+1}, Step {step+1}, Loss: {loss.item()}, article Loss: {loss1.item()}, accusation Loss: {loss2.item()}, penalty Loss: {loss3.item()}\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"{name} grad norm: {param.grad.norm()}\")\n",
    "                break\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "penalty_strings = {\n",
    "    0: \"death_penalty or life_imprisonment\",\n",
    "    1: \"(10 years - ∞)\",\n",
    "    2: \"(7 years - 10 years]\",\n",
    "    3: \"(5 years - 7 years]\",\n",
    "    4: \"(3 years - 5 years]\",\n",
    "    5: \"(2 years - 3 years]\",\n",
    "    6: \"(1 year - 2 years]\",\n",
    "    7: \"(9 months - 12 months]\",\n",
    "    8: \"(6 months - 9 months]\",\n",
    "    9: \"(0 - 6 months]\",\n",
    "    10: \"0\"\n",
    "}\n",
    "\n",
    "\n",
    "article_labels_all = []\n",
    "article_preds_all = []\n",
    "accusation_labels_all = []\n",
    "accusation_preds_all = []\n",
    "penalty_labels_all = []\n",
    "penalty_preds_all = []\n",
    "\n",
    "\n",
    "test_data = load_jsonlines('test_data7050.json')\n",
    "true_imprisonments = []\n",
    "for item in test_data:\n",
    "    term = item['meta']['term_of_imprisonment']\n",
    "    if term['death_penalty']:\n",
    "        imprisonment = 216  # death_penalty\n",
    "    elif term['life_imprisonment']:\n",
    "        imprisonment = 216  # life_imprisonment\n",
    "    else:\n",
    "        imprisonment = term['imprisonment']\n",
    "    true_imprisonments.append([imprisonment])\n",
    "\n",
    "\n",
    "output_file = \"prediction_results.txt\"\n",
    "comparison_file = \"imprisonment_comparison.txt\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f, open(comparison_file, 'w', encoding='utf-8') as cf:\n",
    "    line_num = 0\n",
    "    pred_imprisonments = []\n",
    "    cf.write(\"Line\\tPred_Term_Index\\tPred_Term_Str\\tTrue_Term_Index\\tTrue_Term_Str\\tPred_Months\\tTrue_Months\\tMatch\\n\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(test_dataloader, desc=\"Testing\")):\n",
    "            model.eval()\n",
    "            facts_embedding = batch[0].to(device)\n",
    "            article_labels = batch[1].to(device)\n",
    "            accusation_labels = batch[2].to(device)\n",
    "            penalty_labels = batch[3].to(device)\n",
    "            o = model(facts_embedding)\n",
    "            \n",
    "            article_preds_raw = torch.sigmoid(o[0])\n",
    "            accusation_preds_raw = torch.sigmoid(o[1])\n",
    "            k = 1\n",
    "            _, article_topk_indices = torch.topk(article_preds_raw, k, dim=1)\n",
    "            _, accusation_topk_indices = torch.topk(accusation_preds_raw, k, dim=1)\n",
    "            article_preds = torch.zeros_like(article_preds_raw)\n",
    "            accusation_preds = torch.zeros_like(accusation_preds_raw)\n",
    "            for i in range(article_preds.size(0)):\n",
    "                article_preds[i, article_topk_indices[i]] = 1.0\n",
    "                accusation_preds[i, accusation_topk_indices[i]] = 1.0\n",
    "            \n",
    "            penalty_preds = torch.argmax(o[2], dim=1)\n",
    "            \n",
    "            batch_pred_imprisonments = [[map_term_to_months(pred.item())] for pred in penalty_preds]\n",
    "            pred_imprisonments.extend(batch_pred_imprisonments)\n",
    "            \n",
    "            batch_true_imprisonments = true_imprisonments[line_num:line_num + len(penalty_labels)]\n",
    "            for i in range(len(penalty_labels)):\n",
    "                true_penalty = penalty_labels[i].item()\n",
    "                pred_penalty = penalty_preds[i].item()\n",
    "                true_penalty_str = penalty_strings.get(true_penalty, \"Unknown\")\n",
    "                pred_penalty_str = penalty_strings.get(pred_penalty, \"Unknown\")\n",
    "                pred_months = map_term_to_months(pred_penalty)\n",
    "                true_months = batch_true_imprisonments[i][0]\n",
    "                penalty_match = 1 if true_penalty == pred_penalty else 0\n",
    "                cf.write(f\"{line_num + 1}\\t{pred_penalty}\\t{pred_penalty_str}\\t{true_penalty}\\t{true_penalty_str}\\t{pred_months}\\t{true_months}\\t{penalty_match}\\n\")\n",
    "                line_num += 1\n",
    "\n",
    "                true_article = [int(idx) for idx, val in enumerate(article_labels[i]) if val == 1]\n",
    "                pred_article = [int(idx) for idx, val in enumerate(article_preds[i]) if val == 1]\n",
    "                true_article_str = [id_to_article.get(idx, [\"Unknown article\"])[0] for idx in true_article]\n",
    "                pred_article_str = [id_to_article.get(idx, [\"Unknown article\"])[0] for idx in pred_article]\n",
    "                article_match = 1 if set(true_article) == set(pred_article) else 0\n",
    "                f.write(f\"{line_num} (predict: article, ans: article)\\t{pred_article_str}\\t{true_article_str}\\t{article_match}\\n\")\n",
    "\n",
    "                true_accusation = [int(idx) for idx, val in enumerate(accusation_labels[i]) if val == 1]\n",
    "                pred_accusation = [int(idx) for idx, val in enumerate(accusation_preds[i]) if val == 1]\n",
    "                true_accusation_str = [id_to_crime.get(idx, [\"Unknown accusation\"])[0] for idx in true_accusation]\n",
    "                pred_accusation_str = [id_to_crime.get(idx, [\"Unknown accusation\"])[0] for idx in pred_accusation]\n",
    "                accusation_match = 1 if set(true_accusation) == set(pred_accusation) else 0\n",
    "                f.write(f\"{line_num} (predict: accusation, ans: accusation)\\t{pred_accusation_str}\\t{true_accusation_str}\\t{accusation_match}\\n\")\n",
    "\n",
    "                f.write(f\"{line_num} (predict: penalty, ans: penalty)\\t[{pred_penalty_str}]\\t[{true_penalty_str}]\\t{penalty_match}\\n\")\n",
    "\n",
    "            article_labels_all.extend(article_labels.cpu().numpy())\n",
    "            article_preds_all.extend(article_preds.cpu().numpy())\n",
    "            accusation_labels_all.extend(accusation_labels.cpu().numpy())\n",
    "            accusation_preds_all.extend(accusation_preds.cpu().numpy())\n",
    "            penalty_labels_all.extend(penalty_labels.cpu().numpy())\n",
    "            penalty_preds_all.extend(penalty_preds.cpu().numpy())\n",
    "\n",
    "\n",
    "imprisonment_metrics = calculate_imprisonment_score(true_imprisonments, pred_imprisonments)\n",
    "with open(output_file, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"\\nImprisonment Normalized Score: {imprisonment_metrics['score']:.3f}\\n\")\n",
    "    f.write(f\"Imprisonment Abstention Rate: {imprisonment_metrics['abstention_rate']:.3f}\\n\")\n",
    "\n",
    "\n",
    "true_articles_bin = np.array(article_labels_all)\n",
    "pred_articles_bin = np.array(article_preds_all)\n",
    "true_accusations_bin = np.array(accusation_labels_all)\n",
    "pred_accusations_bin = np.array(accusation_preds_all)\n",
    "true_imprisonments_bin = np.array(penalty_labels_all)\n",
    "pred_imprisonments_bin = np.array(penalty_preds_all)\n",
    "\n",
    "\n",
    "def compute_confusion_matrix(true_bin, pred_bin, num_labels):\n",
    "    res = [{\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0} for _ in range(num_labels)]\n",
    "    for i in range(num_labels):\n",
    "        y_true = true_bin[:, i]\n",
    "        y_pred = pred_bin[:, i]\n",
    "        res[i][\"TP\"] = int((y_true * y_pred).sum())\n",
    "        res[i][\"FN\"] = int((y_true * (1 - y_pred)).sum())\n",
    "        res[i][\"FP\"] = int(((1 - y_true) * y_pred).sum())\n",
    "        res[i][\"TN\"] = int(((1 - y_true) * (1 - y_pred)).sum())\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_value(res):\n",
    "    if res[\"TP\"] == 0:\n",
    "        if res[\"FP\"] == 0 and res[\"FN\"] == 0:\n",
    "            precision = 1.0\n",
    "            recall = 1.0\n",
    "            f1 = 1.0\n",
    "        else:\n",
    "            precision = 0.0\n",
    "            recall = 0.0\n",
    "            f1 = 0.0\n",
    "    else:\n",
    "        precision = 1.0 * res[\"TP\"] / (res[\"TP\"] + res[\"FP\"]) if (res[\"TP\"] + res[\"FP\"]) > 0 else 0.0\n",
    "        recall = 1.0 * res[\"TP\"] / (res[\"TP\"] + res[\"FN\"]) if (res[\"TP\"] + res[\"FN\"]) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def gen_result(res):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    total = {\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "    for a in range(len(res)):\n",
    "        total[\"TP\"] += res[a][\"TP\"]\n",
    "        total[\"FP\"] += res[a][\"FP\"]\n",
    "        total[\"FN\"] += res[a][\"FN\"]\n",
    "        total[\"TN\"] += res[a][\"TN\"]\n",
    "        p, r, f = get_value(res[a])\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    macro_precision = sum(precision) / len(precision) if precision else 0.0\n",
    "    macro_recall = sum(recall) / len(recall) if recall else 0.0\n",
    "    macro_f1 = sum(f1) / len(f1) if f1 else 0.0\n",
    "\n",
    "    return macro_precision, macro_recall, macro_f1\n",
    "\n",
    "\n",
    "def imprisonment_multi_label_accuracy(true_labels, pred_labels):\n",
    "    correct = np.sum(np.all(true_labels == pred_labels, axis=1))\n",
    "    total = len(true_labels)\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "def multi_label_accuracy(true_labels, pred_labels):\n",
    "    correct = 0\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        true_set = set(np.where(true == 1)[0])\n",
    "        pred_set = set(np.where(pred == 1)[0])\n",
    "        if true_set == pred_set or true_set.issubset(pred_set) or pred_set.issubset(true_set):\n",
    "            correct += 1\n",
    "    total = len(true_labels)\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "\n",
    "articles_acc = multi_label_accuracy(true_articles_bin, pred_articles_bin)\n",
    "accusations_acc = multi_label_accuracy(true_accusations_bin, pred_accusations_bin)\n",
    "imprisonments_acc = imprisonment_multi_label_accuracy(np.eye(penalty_num)[true_imprisonments_bin], np.eye(penalty_num)[pred_imprisonments_bin])\n",
    "\n",
    "res_articles = compute_confusion_matrix(true_articles_bin, pred_articles_bin, article_num)\n",
    "macro_p_a, macro_r_a, macro_f_a = gen_result(res_articles)\n",
    "res_accusations = compute_confusion_matrix(true_accusations_bin, pred_accusations_bin, accusation_num)\n",
    "macro_p_c, macro_r_c, macro_f_c = gen_result(res_accusations)\n",
    "res_imprisonments = compute_confusion_matrix(np.eye(penalty_num)[true_imprisonments_bin], np.eye(penalty_num)[pred_imprisonments_bin], penalty_num)\n",
    "macro_p_i, macro_r_i, macro_f_i = gen_result(res_imprisonments)\n",
    "\n",
    "\n",
    "# print(\"relevant_articles:\")\n",
    "print(\"Law_Articles:\")\n",
    "print(f\"  Accuracy: {articles_acc:.3f}\")\n",
    "print(f\"  Macro Precision: {macro_p_a:.3f}\")\n",
    "print(f\"  Macro Recall: {macro_r_a:.3f}\")\n",
    "print(f\"  Macro F1: {macro_f_a:.3f}\")\n",
    "\n",
    "# print(\"accusation:\")\n",
    "print(\"Charges:\")\n",
    "print(f\"  Accuracy: {accusations_acc:.3f}\")\n",
    "print(f\"  Macro Precision: {macro_p_c:.3f}\")\n",
    "print(f\"  Macro Recall: {macro_r_c:.3f}\")\n",
    "print(f\"  Macro F1: {macro_f_c:.3f}\")\n",
    "\n",
    "# print(\"imprisonment:\")\n",
    "print(\" Terms of Penalty:\")\n",
    "print(f\"  Accuracy: {imprisonments_acc:.3f}\")\n",
    "print(f\"  Macro Precision: {macro_p_i:.3f}\")\n",
    "print(f\"  Macro Recall: {macro_r_i:.3f}\")\n",
    "print(f\"  Macro F1: {macro_f_i:.3f}\")\n",
    "print(f\"  Normalized Score: {imprisonment_metrics['score']:.3f}\")\n",
    "print(f\"  Abstention Rate: {imprisonment_metrics['abstention_rate']:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
